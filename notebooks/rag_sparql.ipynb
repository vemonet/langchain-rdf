{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶ô RAG for SPARQL queries\n",
    "\n",
    "Demo of **Retrieval Augmented Generation** (RAG) to faithfully resolve and use concepts from an OWL ontology, with conversation memory, running locally, using only open source components:\n",
    "* [LangChain](https://python.langchain.com) (cf. docs: [RAG with memory](https://python.langchain.com/docs/expression_language/cookbook/retrieval), [streaming RAG](https://python.langchain.com/docs/use_cases/question_answering/streaming))\n",
    "* [FastEmbed embeddings](https://github.com/qdrant/fastembed)\n",
    "* [Qdrant vectorstore](https://github.com/qdrant/qdrant)\n",
    "* [LlamaCpp inference library](https://github.com/ggerganov/llama.cpp)\n",
    "* [Mixtral 8x7B LLM](https://mistral.ai/news/mixtral-of-experts/)\n",
    "\n",
    "This demo runs locally on CPU and GPU, but will be considerably slow on CPU (a few minutes to answer the question).\n",
    "\n",
    "You can easily change the different components used in this workflow to use whatever you prefer thanks to LangChain: \n",
    "* LLM (e.g. switch to [ChatGPT](https://python.langchain.com/docs/integrations/llms/openai), Claude)\n",
    "* Vectorstore (e.g. switch to [FAISS](https://python.langchain.com/docs/integrations/vectorstores/faiss), [Chroma](https://python.langchain.com/docs/integrations/vectorstores/chroma), Milvus)\n",
    "* Embedding model (e.g. switch to [HuggingFace sentence transformer](https://python.langchain.com/docs/integrations/text_embedding/sentence_transformers), OpenAI ADA)\n",
    "\n",
    "## üì¶Ô∏è Install and import dependencies\n",
    "\n",
    "‚ö†Ô∏è Install `ollama`: https://ollama.com/download\n",
    "\n",
    "And pull the model you will use:\n",
    "\n",
    "```bash\n",
    "ollama pull llama3\n",
    "```\n",
    "\n",
    "> Make sure to pick up a model already fine-tuned for chat (they have `instruct` or `chat` in their name usually)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --quiet langchain langchain-community llama-cpp-python langchain-qdrant fastembed langchain-openai\n",
    "\n",
    "from operator import itemgetter\n",
    "from typing import Any\n",
    "\n",
    "from langchain.globals import set_debug\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.schema import format_document\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import get_buffer_string\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_rdf import SparqlExamplesLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåÄ Initialize local vectorstore and LLM\n",
    "\n",
    "```\n",
    "flag_embeddings_size = 384\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e30470504942ea826be9bf13db10f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_model = FastEmbedEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\", max_length=512)\n",
    "loader = SparqlExamplesLoader(\"https://sparql.uniprot.org/sparql/\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split the documents into chunks if necessary\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    docs,\n",
    "    embedding_model,\n",
    "    collection_name=\"ontologies\",\n",
    "    location=\":memory:\",\n",
    "    # path=\"./data/qdrant\",\n",
    "    # Run Qdrant as a service for production use:\n",
    "    # url=\"http://localhost:6333\",\n",
    "    # prefer_grpc=True,\n",
    ")\n",
    "# vectorstore = FAISS.from_documents(documents=docs, embedding=flag_embeddings)\n",
    "# K is the number of source documents retrieved\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"gpt-4o\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "#     # api_key=\"...\",  # if you prefer to pass api key in directly instead of using env vars\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Initialize prompts and memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the memory object that is used to add messages\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
    ")\n",
    "# Add a \"memory\" key to the input object\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
    ")\n",
    "\n",
    "# Prompt to reformulate the question using the chat history\n",
    "reform_template = \"\"\"Given the following chat history and a follow up question,\n",
    "rephrase the follow up question to be a standalone straightforward question, in its original language.\n",
    "Do not answer the question! Just rephrase reusing informations from the chat history.\n",
    "Make it short and straight to the point.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "REFORM_QUESTION_PROMPT = ChatPromptTemplate.from_template(reform_template)\n",
    "\n",
    "# Prompt to ask to answer the reformulated question\n",
    "answer_template = \"\"\"Briefly answer the question based only on the following context,\n",
    "do not use any information outside this context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(answer_template)\n",
    "\n",
    "# Format how the ontology concepts are passed as context to the LLM\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(\n",
    "    template=\"User question: {page_content}\\n```sparql\\n# {endpoint_url}\\n{query}```\"\n",
    ")\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    print(docs)\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    # print(\"Formatted docs:\", doc_strings)\n",
    "    return document_separator.join(doc_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚õìÔ∏è Define the chain\n",
    "\n",
    "`itemgetter()` is used to retrieve objects defined in the previous step in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformulate the question using chat history\n",
    "reformulated_question = {\n",
    "    \"reformulated_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
    "    }\n",
    "    | REFORM_QUESTION_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser(),\n",
    "}\n",
    "# Retrieve the documents using the reformulated question\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"reformulated_question\") | retriever,\n",
    "    \"question\": lambda x: print(\"üí≠ Reformulated question:\", x[\"reformulated_question\"]) or x[\"reformulated_question\"],\n",
    "    # \"question\": lambda x: x[\"reformulated_question\"],\n",
    "}\n",
    "# Construct the inputs for the final prompt using retrieved documents\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "# Generate the answer using the retrieved documents and answer prompt\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | llm,\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "}\n",
    "# Put the chain together\n",
    "final_chain = loaded_memory | reformulated_question | retrieved_documents | answer\n",
    "\n",
    "def stream_chain(final_chain, memory: ConversationBufferMemory, inputs: dict[str, str]) -> dict[str, Any]:\n",
    "    \"\"\"Ask question, stream the answer output, and return the answer with source documents.\"\"\"\n",
    "    output = {\"answer\": \"\"}\n",
    "    for chunk in final_chain.stream(inputs):\n",
    "        # print(chunk)\n",
    "        if \"docs\" in chunk:\n",
    "            output[\"docs\"] = [doc.dict() for doc in chunk[\"docs\"]]\n",
    "            print(\"üìö Documents retrieved:\")\n",
    "            for doc in output[\"docs\"]:\n",
    "                print(f\"¬∑ {doc['page_content']}\") # ({doc['metadata']['query']})\n",
    "            # print(json.dumps(output[\"docs\"], indent=2))\n",
    "        if \"answer\" in chunk:\n",
    "            # OpenAI response vs llama.cpp response\n",
    "            chunk_str = chunk[\"answer\"].content if hasattr(chunk[\"answer\"], \"content\") else chunk[\"answer\"]\n",
    "            output[\"answer\"] += chunk_str\n",
    "            print(chunk_str, end=\"\", flush=True)\n",
    "    # Add message to chat history\n",
    "    memory.save_context(inputs, {\"answer\": output[\"answer\"]})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üó®Ô∏è Ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí≠ Reformulated question: What is the method to obtain the HGNC symbol for a protein?\n",
      "üìö Documents retrieved:\n",
      "¬∑ Map UniProt to HGNC identifiers and Symbols\n",
      "¬∑ Find UniProt entries with a transmembrane region, with an Alanine in the 15 Aminoacid region preceding the transmembrane\n",
      "¬∑ Find enzymes with a Tyrosine (Y) as an active site\n",
      "¬∑ Find all proteins linked to arachidonate (CHEBI:32395)\n",
      "¬∑ Find the human protein which contains an Epitope VSTQ, where T is a phosporylated threonine\n",
      "[Document(page_content='Map UniProt to HGNC identifiers and Symbols', metadata={'comment': 'Map UniProt to HGNC identifiers and Symbols', 'query': \"PREFIX up: <http://purl.uniprot.org/core/>\\nPREFIX uniprotkb: <http://purl.uniprot.org/uniprot/>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nSELECT\\n  ?uniprot\\n  ?hgnc\\n  ?hgncSymbol\\nWHERE\\n{\\n  # A space separated list of UniProt primary accessions.\\n  VALUES (?acc) {('P05067') ('P00750')}\\n  BIND(iri(concat(str(uniprotkb:), ?acc)) AS ?uniprot)\\n  ?uniprot rdfs:seeAlso ?hgnc .\\n  ?hgnc up:database <http://purl.uniprot.org/database/HGNC> ;\\n       rdfs:comment ?hgncSymbol .\\n}\", 'endpoint_url': 'https://sparql.uniprot.org/sparql/', 'query_type': 'SelectQuery', '_id': 'b08be273ab5b447f9517aceaff730ec5', '_collection_name': 'ontologies'}), Document(page_content='Find UniProt entries with a transmembrane region, with an Alanine in the 15 Aminoacid region preceding the transmembrane', metadata={'comment': 'Find UniProt entries with a transmembrane region, with an Alanine in the 15 Aminoacid region preceding the transmembrane', 'query': \"PREFIX up: <http://purl.uniprot.org/core/>\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX faldo: <http://biohackathon.org/resource/faldo#>\\n\\nSELECT ?protein ?from ?interestingRegion\\nWHERE\\n{\\n  ?protein up:annotation ?annotation .\\n  ?annotation a up:Transmembrane_Annotation .\\n  # Get the coordinates of the Transmembrane\\n  ?annotation up:range ?range .\\n  ?range faldo:begin ?beginI .\\n  ?beginI faldo:position ?begin .\\n  ?beginI faldo:reference ?sequence .\\n  # The aas will have the specific IUPAC aminoacids\\n  ?sequence rdf:value ?aas .\\n  # We calculate the start by substracting 10\\n  BIND(?begin - 10 AS ?tenBeforeBegin)\\n  # Can't start before the sequence starts or we might miss some results\\n  BIND(IF(?tenBeforeBegin < 1, 0, ?tenBeforeBegin) AS ?from)\\n  # Substring the IUPAC aminoacids\\n  BIND(SUBSTR(?aas, ?from, 15) AS ?interestingRegion)\\n  # The interestingRegion needds to contain an Alanine\\n  FILTER(CONTAINS(?interestingRegion, 'A'))\\n}\\n\", 'endpoint_url': 'https://sparql.uniprot.org/sparql/', 'query_type': 'SelectQuery', '_id': '2db30d308a2d492fa31ebbbab023e4cf', '_collection_name': 'ontologies'}), Document(page_content='Find enzymes with a Tyrosine (Y) as an active site', metadata={'comment': 'Find enzymes with a Tyrosine (Y) as an active site', 'query': \"PREFIX up: <http://purl.uniprot.org/core/>\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX faldo: <http://biohackathon.org/resource/faldo#>\\nSELECT \\n  ?protein\\nWHERE {\\n  ?protein up:annotation ?activeSiteAnnotation .\\n  ?activeSiteAnnotation a up:Active_Site_Annotation ;\\n    up:range ?range .\\n  ?range faldo:begin ?begin .\\n  ?begin faldo:position ?beginPosition ;\\n    faldo:reference ?sequence .\\n  ?sequence rdf:value ?sequenceVal . \\n  FILTER(SUBSTR(?sequenceVal, ?beginPosition, 1) = 'Y')\\n}\", 'endpoint_url': 'https://sparql.uniprot.org/sparql/', 'query_type': 'SelectQuery', '_id': 'c3d4c4f97c4e4bf8bcfaf4dbb8af09e6', '_collection_name': 'ontologies'}), Document(page_content='Find all proteins linked to arachidonate (CHEBI:32395)', metadata={'comment': 'Find all proteins linked to arachidonate (CHEBI:32395)', 'query': 'PREFIX up: <http://purl.uniprot.org/core/>\\nPREFIX skos: <http://www.w3.org/2004/02/skos/core#>\\nPREFIX rh: <http://rdf.rhea-db.org/>\\nPREFIX CHEBI: <http://purl.obolibrary.org/obo/CHEBI_>\\n\\nSELECT \\n    DISTINCT\\n        ?uniprot\\n        ?uniprotID\\n        ?recname\\n        ?gene\\n        ?chebi\\n        ?uniprotName\\nWHERE {\\n  SERVICE <https://sparql.rhea-db.org/sparql> {\\n     VALUES (?chebi) { (CHEBI:32395) }\\n     ?rhea rh:side/rh:contains/rh:compound ?compound .\\n     ?compound rh:chebi ?chebi .\\n     ?chebi up:name ?uniprotName .\\n  }\\n  ?uniprot up:annotation/up:catalyticActivity/up:catalyzedReaction ?rhea .\\n  ?uniprot up:mnemonic ?uniprotID .\\n  ?uniprot up:recommendedName/up:fullName ?recname .\\n  OPTIONAL {?uniprot up:encodedBy/skos:prefLabel ?gene .}\\n}', 'endpoint_url': 'https://sparql.uniprot.org/sparql/', 'query_type': 'SelectQuery', '_id': 'e806b8a741f74efa859ccdc91995ccf8', '_collection_name': 'ontologies'}), Document(page_content='Find the human protein which contains an Epitope VSTQ, where T is a phosporylated threonine', metadata={'comment': 'Find the human protein which contains an Epitope VSTQ, where T is a phosporylated threonine', 'query': 'PREFIX up: <http://purl.uniprot.org/core/>\\nPREFIX taxon: <http://purl.uniprot.org/taxonomy/>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX faldo: <http://biohackathon.org/resource/faldo#>\\nSELECT \\n  ?protein \\n  ?comment\\n  ?begin\\n  ?end \\nWHERE\\n{\\n  ?protein a up:Protein ;\\n    up:organism taxon:9606 ; \\n    up:sequence ?sequence ;\\n    up:annotation ?annotation .\\n  ?annotation a up:Modified_Residue_Annotation ;\\n    rdfs:comment ?comment ;\\n    up:range ?range .\\n  ?range \\n    faldo:begin [ faldo:position ?begin ; faldo:reference ?sequence ] ;\\n    faldo:end [ faldo:position ?end ; faldo:reference ?sequence ] .\\n  ?sequence rdf:value ?aaSequence .\\n  FILTER (SUBSTR(?aaSequence, ?begin -2 , 4) = \"VSTQ\")     \\n  FILTER (CONTAINS(?comment, \"Phosphothreonine\"))\\n}\\n', 'endpoint_url': 'https://sparql.uniprot.org/sparql/', 'query_type': 'SelectQuery', '_id': 'c0625521baf9412d9b7c3ffe1f6aa1ea', '_collection_name': 'ontologies'})]\n",
      "Based on the provided context, the method to obtain the HGNC symbol for a protein is by querying the UniProt database using SPARQL. The relevant part of the query is:\n",
      "\n",
      "```sparql\n",
      "?uniprot rdfs:seeAlso ?hgnc .\n",
      "?hgnc up:database <http://purl.uniprot.org/database/HGNC> ;\n",
      "       rdfs:comment ?hgncSymbol .\n",
      "```\n",
      "\n",
      "This part of the query finds a protein (`?uniprot`) that is associated with an HGNC entry (`?hgnc`) through the `rdfs:seeAlso` property. Then, it extracts the HGNC symbol from the HGNC entry using the `rdfs:comment` property."
     ]
    }
   ],
   "source": [
    "# set_debug(True)   # Uncomment to enable detailed LangChain debugging\n",
    "output = stream_chain(final_chain, memory, {\n",
    "    \"question\": \"How can I retrieve the HGNC symbol for a protein?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí≠ Reformulated question: What is the complete SPARQL query to retrieve the HGNC symbol for protein P68871?\n",
      "üìö Documents retrieved:\n",
      "¬∑ Find the orthologous proteins for UniProtKB entry P05067 using the <a href=\"http://www.orthod.org\">OrthoDB database</a>\n",
      "¬∑ Map UniProt to HGNC identifiers and Symbols\n",
      "¬∑ For the human entry P05067 (Amyloid-beta precursor protein) find the gene start ends in WikiData\n",
      "¬∑ Find the human protein which contains an Epitope VSTQ, where T is a phosporylated threonine\n",
      "¬∑ Find any uniprot entry, or an uniprot entries domain or component which has a name 'HLA class I histocompatibility antigen, B-73 alpha chain'\n",
      "[Document(page_content='Find the orthologous proteins for UniProtKB entry P05067 using the <a href=\"http://www.orthod.org\">OrthoDB database</a>', metadata={'comment': 'Find the orthologous proteins for UniProtKB entry P05067 using the <a href=\"http://www.orthod.org\">OrthoDB database</a>', 'query': 'PREFIX up: <http://purl.uniprot.org/core/>\\nPREFIX uniprotkb: <http://purl.uniprot.org/uniprot/>\\nPREFIX skos: <http://www.w3.org/2004/02/skos/core#>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX orthodb: <http://purl.orthodb.org/>\\nSELECT \\n  ?protein \\n  ?orthoGroup\\n  ?scientificName \\n  ?functionComment \\n  ?prefferedGeneName \\n  ((STRLEN(?value) - ?medianLength) as ?deviationFromMedianLength)\\nWHERE\\n{\\n  uniprotkb:P05067 a up:Protein ;\\n        up:organism/up:scientificName ?scientificName ;\\n        rdfs:seeAlso ?orthoGroup ;\\n        up:encodedBy/skos:prefLabel ?prefferedGeneName ;\\n             up:sequence/rdf:value ?value .\\n  OPTIONAL {\\n     ?protein up:annotation ?functionAnnotation .\\n     ?functionAnnotation a up:Function_Annotation ;\\n                         rdfs:comment ?functionComment .\\n  }\\n  SERVICE<https://sparql.orthodb.org/sparql>{\\n    ?orthoGroup orthodb:ogMedianProteinLength ?medianLength .\\n    ?orthoGroup orthodb:hasMember ?xref .\\n    ?xref orthodb:xref/orthodb:xrefResource uniprotkb:P05067 .\\n  }\\n}\\n', 'endpoint_url': 'https://sparql.uniprot.org/sparql/', 'query_type': 'SelectQuery', '_id': '12ac8db5312f4de6a01a2f2af896943d', '_collection_name': 'ontologies'}), Document(page_content='Map UniProt to HGNC identifiers and Symbols', metadata={'comment': 'Map UniProt to HGNC identifiers and Symbols', 'query': \"PREFIX up: <http://purl.uniprot.org/core/>\\nPREFIX uniprotkb: <http://purl.uniprot.org/uniprot/>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nSELECT\\n  ?uniprot\\n  ?hgnc\\n  ?hgncSymbol\\nWHERE\\n{\\n  # A space separated list of UniProt primary accessions.\\n  VALUES (?acc) {('P05067') ('P00750')}\\n  BIND(iri(concat(str(uniprotkb:), ?acc)) AS ?uniprot)\\n  ?uniprot rdfs:seeAlso ?hgnc .\\n  ?hgnc up:database <http://purl.uniprot.org/database/HGNC> ;\\n       rdfs:comment ?hgncSymbol .\\n}\", 'endpoint_url': 'https://sparql.uniprot.org/sparql/', 'query_type': 'SelectQuery', '_id': 'b08be273ab5b447f9517aceaff730ec5', '_collection_name': 'ontologies'}), Document(page_content='For the human entry P05067 (Amyloid-beta precursor protein) find the gene start ends in WikiData', metadata={'comment': 'For the human entry P05067 (Amyloid-beta precursor protein) find the gene start ends in WikiData', 'query': 'PREFIX wdt: <http://www.wikidata.org/prop/direct/>\\nPREFIX uniprotkb: <http://purl.uniprot.org/uniprot/>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nPREFIX ps: <http://www.wikidata.org/prop/statement/>\\nPREFIX pq: <http://www.wikidata.org/prop/qualifier/>\\nPREFIX p: <http://www.wikidata.org/prop/>\\n\\nSELECT \\n\\t?protein \\n\\t?begin\\n\\t?end\\n\\t?chromosome\\n\\t?assembly\\nWHERE {\\n    {\\n        BIND(uniprotkb:P05067 AS ?proteinIRI)\\n        BIND (SUBSTR(STR(?proteinIRI), STRLEN(STR(uniprotkb:))+1) AS ?protein)\\n    }\\n    SERVICE <https://query.wikidata.org/sparql> {\\n        ?wp wdt:P352 ?protein ;\\n            wdt:P702 ?wg . \\n        ?wg p:P644   ?wgss .\\n        ?wgss ps:P644        ?begin ;\\n          pq:P1057/wdt:P1813 ?chromosome ;\\n          pq:P659/rdfs:label ?assembly .\\n        ?wg p:P645 ?wgse .\\n        ?wgse ps:P645        ?end ;\\n          pq:P1057/wdt:P1813 ?chromosome ;\\n          pq:P659/rdfs:label ?assembly .\\n        FILTER(lang(?assembly) = \"en\")\\n  } \\n}\\n', 'endpoint_url': 'https://sparql.uniprot.org/sparql/', 'query_type': 'SelectQuery', '_id': '91a82a5fc26e4e99b13b12ca275af89b', '_collection_name': 'ontologies'}), Document(page_content='Find the human protein which contains an Epitope VSTQ, where T is a phosporylated threonine', metadata={'comment': 'Find the human protein which contains an Epitope VSTQ, where T is a phosporylated threonine', 'query': 'PREFIX up: <http://purl.uniprot.org/core/>\\nPREFIX taxon: <http://purl.uniprot.org/taxonomy/>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX faldo: <http://biohackathon.org/resource/faldo#>\\nSELECT \\n  ?protein \\n  ?comment\\n  ?begin\\n  ?end \\nWHERE\\n{\\n  ?protein a up:Protein ;\\n    up:organism taxon:9606 ; \\n    up:sequence ?sequence ;\\n    up:annotation ?annotation .\\n  ?annotation a up:Modified_Residue_Annotation ;\\n    rdfs:comment ?comment ;\\n    up:range ?range .\\n  ?range \\n    faldo:begin [ faldo:position ?begin ; faldo:reference ?sequence ] ;\\n    faldo:end [ faldo:position ?end ; faldo:reference ?sequence ] .\\n  ?sequence rdf:value ?aaSequence .\\n  FILTER (SUBSTR(?aaSequence, ?begin -2 , 4) = \"VSTQ\")     \\n  FILTER (CONTAINS(?comment, \"Phosphothreonine\"))\\n}\\n', 'endpoint_url': 'https://sparql.uniprot.org/sparql/', 'query_type': 'SelectQuery', '_id': 'c0625521baf9412d9b7c3ffe1f6aa1ea', '_collection_name': 'ontologies'}), Document(page_content=\"Find any uniprot entry, or an uniprot entries domain or component which has a name 'HLA class I histocompatibility antigen, B-73 alpha chain'\", metadata={'comment': \"Find any uniprot entry, or an uniprot entries domain or component which has a name 'HLA class I histocompatibility antigen, B-73 alpha chain'\", 'query': 'PREFIX up: <http://purl.uniprot.org/core/>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nSELECT ?protein ?anyKindOfName\\nWHERE\\n{\\n\\t\\t?protein a up:Protein .\\n\\t\\t?protein (up:recommendedName|up:alternativeName)|((up:domain|up:component)/(up:recommendedName|up:alternativeName)) ?structuredName .\\n\\t\\t?structuredName ?anyKindOfName  \"HLA class I histocompatibility antigen, B-73 alpha chain\" .\\n\\t\\t?anyKindOfName rdfs:subPropertyOf up:structuredNameType .\\n}', 'endpoint_url': 'https://sparql.uniprot.org/sparql/', 'query_type': 'SelectQuery', '_id': 'fa3569ea72af4a458e04fda43073f562', '_collection_name': 'ontologies'})]\n",
      "The complete SPARQL query to retrieve the HGNC symbol for protein P68871 would be:\n",
      "\n",
      "```sparql\n",
      "# https://sparql.uniprot.org/sparql/\n",
      "PREFIX up: <http://purl.uniprot.org/core/>\n",
      "PREFIX uniprotkb: <http://purl.uniprot.org/uniprot/>\n",
      "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      "SELECT\n",
      "  ?uniprot\n",
      "  ?hgnc\n",
      "  ?hgncSymbol\n",
      "WHERE\n",
      "{\n",
      "  # A space separated list of UniProt primary accessions.\n",
      "  VALUES (?acc) {('P68871')}\n",
      "  BIND(iri(concat(str(uniprotkb:), ?acc)) AS ?uniprot)\n",
      "  ?uniprot rdfs:seeAlso ?hgnc .\n",
      "  ?hgnc up:database <http://purl.uniprot.org/database/HGNC> ;\n",
      "       rdfs:comment ?hgncSymbol .\n",
      "}\n",
      "```"
     ]
    }
   ],
   "source": [
    "# set_debug(True)   # Uncomment to enable detailed LangChain debugging\n",
    "output = stream_chain(final_chain, memory, {\n",
    "    \"question\": \"Could you write the complete query for protein P68871?\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libre-chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
